# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.
Original file is located at
    https://colab.research.google.com/drive/1qZko9zcrVpAT_EdWSXGEbwcwr4Rflk9p
"""

# === app.py Code (Full Version - Modified for Whisper) ===
import streamlit as st
import requests # Still useful for general web requests, though not for AAI now
import json # Still useful
import time # Still useful
import os
from moviepy.editor import VideoFileClip # For extracting audio from video

# Import Whisper
import whisper # This imports the Whisper library

# No API key needed for Whisper local model!
# Remove the try-except block for ASSEMBLYAI_API_KEY as it's no longer needed.
# try:
#     ASSEMBLYAI_API_KEY = st.secrets["assemblyai_api_key"]
# except KeyError:
#     st.error("AssemblyAI API Key not found in Streamlit Secrets. Please add it to your Streamlit Cloud app settings.")
#     st.stop() # Stop the app if key is missing

# Remove AssemblyAI API Endpoints as they are no longer used
# UPLOAD_ENDPOINT = "https://api.assemblyai.com/v2/upload"
# TRANSCRIPT_ENDPOINT = "https://api.assemblyai.com/v2/transcript"
# headers = {
#     "authorization": ASSEMBLYAI_API_KEY,
#     "content-type": "application/json"
# }


# --- Functions ---

# Remove AssemblyAI-specific functions
# def upload_file_to_assemblyai(filepath): ...
# def submit_for_transcription_and_translation(audio_url): ...
# def get_transcript_result(transcript_id): ...
# def generate_srt_from_translation(transcript_id): ...


def extract_audio_from_video(video_path, audio_output_path="temp_audio.mp3"):
    """Extracts audio from a video file using moviepy."""
    try:
        video = VideoFileClip(video_path)
        video.audio.write_audiofile(audio_output_path)
        return audio_output_path
    except Exception as e:
        st.error(f"Error extracting audio from video: {e}")
        return None

# --- NEW: Whisper-specific functions ---

@st.cache_resource # This decorator caches the model, so it's loaded only once
def load_whisper_model(model_size="base"):
    """Loads the Whisper model into memory. Caches to prevent re-loading on every rerun."""
    st.info(f"Loading Whisper '{model_size}' model. This may take a moment...")
    try:
        model = whisper.load_model(model_size)
        st.success(f"Whisper '{model_size}' model loaded successfully!")
        return model
    except Exception as e:
        st.error(f"Error loading Whisper model: {e}")
        st.stop() # Stop the app if model fails to load

def transcribe_and_translate_with_whisper(audio_path, model):
    """
    Transcribes audio and translates to English using the loaded Whisper model.
    """
    st.info("Starting transcription and translation with Whisper...")
    try:
        # Whisper can automatically detect language and translate to English
        # 'task="translate"' means translate source language to English
        # 'verbose=True' will show more details in Streamlit logs during processing
        result = model.transcribe(audio_path, task="translate", verbose=True)

        # 'result' will contain the full translated text and a list of segments
        return result
    except Exception as e:
        st.error(f"Error during Whisper transcription/translation: {e}")
        return None

def generate_srt_from_whisper_segments(segments):
    """
    Generates SRT content from Whisper's segment output.
    """
    srt_content = []
    for i, segment in enumerate(segments):
        # Whisper segment times are in seconds (floats)
        start_time = segment['start']
        end_time = segment['end']
        text = segment['text'].strip()

        # Format time for SRT (HH:MM:SS,ms)
        def format_time(seconds):
            milliseconds = int((seconds - int(seconds)) * 1000)
            seconds = int(seconds)
            hours = seconds // 3600
            minutes = (seconds % 3600) // 60
            seconds = seconds % 60
            return f"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}"

        srt_content.append(str(i + 1)) # Subtitle index
        srt_content.append(f"{format_time(start_time)} --> {format_time(end_time)}")
        srt_content.append(text)
        srt_content.append("") # Empty line between segments for SRT format
    return "\n".join(srt_content)

# Remove the existing process_srt_file_for_translation as Whisper works with audio
def process_srt_file_for_translation(srt_file_path):
    """
    Processes an SRT file by extracting text, and then attempts to translate it.
    NOTE: Direct SRT translation with timecode preservation is complex.
    This function will simply extract text and send to a generic translation service (conceptual).
    For perfect timecode preservation, extracting audio from video/audio and then using AAI's full service is recommended.
    """
    st.warning("Translating an existing SRT file while preserving perfect timecodes is complex.")
    st.warning("For best results, use the 'Upload Video File' option with your original video or audio.")

    try:
        extracted_text = ""
        with open(srt_file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                # Skip index numbers and timecodes
                if line.isdigit() or '-->' in line or not line:
                    continue
                extracted_text += line + " " # Append text with a space

        if not extracted_text.strip():
            st.error("No translatable text found in the SRT file.")
            return None

        st.info("This feature is experimental and does not use Whisper for direct SRT translation.")
        st.info("You would typically use a dedicated text translation API like Google Cloud Translation or DeepL for this.")

        # For a simplified demonstration, let's just show the extracted text.
        st.subheader("Extracted Text from SRT:")
        st.write(extracted_text)
        st.warning("To get an SRT output, Whisper needs an audio source.")
        return None # Indicate that direct SRT-to-SRT translation isn't fully supported by this workflow.

    except Exception as e:
        st.error(f"Error processing SRT file: {e}")
        return None


# --- Streamlit UI ---
st.set_page_config(page_title="Universal Subtitle Translator", layout="centered")

st.title("üé¨ Universal Subtitle Translator")
st.markdown("Easily convert Video/SRT files into **English Subtitles** using AI!")

st.markdown("""
<style>
.stButton>button {
    width: 100%;
    border-radius: 0.5rem;
    padding: 0.8rem;
    font-size: 1.1rem;
    background-color: #4CAF50;
    color: white;
    border: none;
    cursor: pointer;
}
.stButton>button:hover {
    background-color: #45a049;
}
.stFileUploader>div>div {
    border-radius: 0.5rem;
    border: 2px dashed #4CAF50;
    padding: 20px;
    text-align: center;
}
</style>
""", unsafe_allow_html=True)

option = st.radio(
    "Choose input type:",
    ('Upload Video File', 'Upload SRT File (Experimental)'),
    horizontal=True
)

# Temporary directory for uploaded files
if not os.path.exists("temp"):
    os.makedirs("temp")

# --- Load Whisper Model at the start of the app ---
# Choose your model size: "tiny", "base", "small", "medium"
# "base" is a good balance for Streamlit Free Tier.
# If you face Memory issues, try "tiny".
whisper_model = load_whisper_model(model_size="base") # Or "tiny" if base causes memory errors


# --- Video File Upload Section ---
if option == 'Upload Video File':
    uploaded_file = st.file_uploader("Upload a video file (e.g., MP4, MOV)", type=["mp4", "mov", "avi", "mkv"])
    if uploaded_file is not None:
        file_details = {"FileName": uploaded_file.name, "FileType": uploaded_file.type, "FileSize": uploaded_file.size}
        st.write(file_details)

        temp_video_path = os.path.join("temp", uploaded_file.name)
        with open(temp_video_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        st.info(f"Processing '{uploaded_file.name}'...")
        
        with st.spinner("Extracting audio..."):
            temp_audio_path = extract_audio_from_video(temp_video_path)
        
        if temp_audio_path:
            # --- PROMPT: This is where the AssemblyAI logic was, now replaced with Whisper ---
            st.info("Audio extracted. Processing with Whisper model...")
            with st.spinner("Transcribing and translating to English with Whisper... This may take a while for large files."):
                whisper_result = transcribe_and_translate_with_whisper(temp_audio_path, whisper_model)
            
            if whisper_result and whisper_result.get("segments"): # Check if segments exist
                st.success("Transcription and Translation completed with Whisper!")
                
                srt_content = generate_srt_from_whisper_segments(whisper_result["segments"])
                
                if srt_content:
                    st.subheader("Generated English SRT:")
                    st.text_area("SRT Content", srt_content, height=300)
                    
                    st.download_button(
                        label="Download English SRT",
                        data=srt_content,
                        file_name=f"{os.path.splitext(uploaded_file.name)[0]}_english.srt",
                        mime="text/plain"
                    )
                else:
                    st.error("Failed to generate SRT content from Whisper results.")
            else:
                st.error("Whisper transcription or translation failed. Please check logs for details.")
        else:
            st.error("Failed to extract audio from the video. Please check video file format or size.")
        
        # Clean up temporary files
        if os.path.exists(temp_audio_path):
            os.remove(temp_audio_path)
        
        if os.path.exists(temp_video_path):
            os.remove(temp_video_path)

elif option == 'Upload SRT File (Experimental)':
    uploaded_srt_file = st.file_uploader("Upload an SRT file (e.g., .srt)", type=["srt"])
    if uploaded_srt_file is not None:
        st.write({"FileName": uploaded_srt_file.name, "FileType": uploaded_srt_file.type, "FileSize": uploaded_srt_file.size})

        temp_srt_path = os.path.join("temp", uploaded_srt_file.name)
        with open(temp_srt_path, "wb") as f:
            f.write(uploaded_srt_file.getbuffer())

        st.info(f"Processing '{uploaded_srt_file.name}'...")

        process_srt_file_for_translation(temp_srt_path) # This function is kept but has limitations

        if os.path.exists(temp_srt_path):
            os.remove(temp_srt_path)

        st.warning("Note: Direct SRT translation with perfect timecode preservation is not fully supported by this workflow's primary method (Whisper). For best results, use the 'Upload Video File' option with your original video or audio.")

st.markdown("---")
st.markdown("Developed with ‚ù§Ô∏è using Whisper (OpenAI) and Streamlit.")
